# -*- coding: utf-8 -*-
"""Telebot_NN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15kUrZ8PSFuaGoKnqYd3NUzMJWaEswDw3
"""

!pip install nltk
!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117

# (stemming, tokenization,bag of words)
# creating training data
# pyTorch model and training
# save/load model and implement the chat
import nltk
nltk.download('punkt')

from nltk.stem.porter import PorterStemmer
stemmer=PorterStemmer()

def tokenize(sentence):
  return nltk.word_tokenize(sentence)

def stem(word):
    return stemmer.stem(word.lower())

def bag_of_words(tokenize_sentence,all_words):
    tokenize_sentence=[stem(w) for w in tokenize_sentence]
    bag=np.zeros(len(all_words),dtype=np.float32)
    for idx,w in enumerate(all_words):
        if w in tokenize_sentence:
            bag[idx]=1.0
    return bag

#model
import torch
import torch.nn as nn

class NeuralNet(nn.Module):
    def __init__(self,input_size,hidden_size,num_classes):
        super(NeuralNet,self).__init__()
        self.l1=nn.Linear(input_size,hidden_size)
        self.l2=nn.Linear(hidden_size,hidden_size)
        self.l3=nn.Linear(hidden_size,num_classes)
        self.relu=nn.ReLU()

    def forward(self,x):
        out=self.l1(x)
        out=self.relu(out)
        out=self.l2(out)
        out=self.relu(out)
        out=self.l3(out)
        #no activation and no softmax
        return out

import json
import numpy as np
# from bot import tokenize,stem,bag_of_words
with open('intents.json','r') as f:
    intents=json.load(f)
import torch
import torch.nn as nn
from torch.utils.data  import Dataset,DataLoader
# from model import NeuralNet

all_words=[]
tags=[]
xy=[]
for intent in intents['intents']:
    tag=intent['tag']
    tags.append(tag)
    for pattern in intent['patterns']:
        w=tokenize(pattern)
        all_words.extend(w)
        xy.append((w,tag))
ignore_words=['?','!','.',',','@','/']
#to ignore the punctuation and steming data
all_words=(stem(w) for w in all_words if w not in ignore_words)
#Sorting to avoid duplicate
all_words=sorted(set(all_words))
tags=sorted(set(tags))

x_train=[]
y_train=[]
#making bag of words
for (pattern_sentence,tag) in xy:
    bag=bag_of_words(pattern_sentence,all_words)
    x_train.append(bag)
    label=tags.index(tag)
    y_train.append(label) #CrossEntropyLoss

x_train=np.array(x_train)
y_train=np.array(y_train)

class ChatDataset(Dataset):
    
    def __init__(self):
        
        self.n_samples=len(x_train)
        self.x_data=x_train
        self.y_data=y_train

    #datasetidx s
    def __getitem__(self,index):
        return self.x_data[index],self.y_data[index]
    
    def __len__(self):
        return self.n_samples
    
batch_size=8
hidden_size=8
output_size=len(tags)
input_size=len(x_train[0])
learning_rate=0.001
num_epochs=1000


dataset=ChatDataset()
train_loader=DataLoader(dataset=dataset,batch_size=batch_size,shuffle=True,num_workers=2)

device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model=NeuralNet(input_size,hidden_size,output_size).to(device)

#loss and optimizer

criterion=nn.CrossEntropyLoss()
optimizer=torch.optim.Adam(model.parameters(),lr=learning_rate)

for epoch in range(num_epochs):
    for(words,labels) in train_loader:
        words=words.to(device)
        labels=labels.to(device)

        #forward
        outputs=model(words)
        loss=criterion(outputs,labels)

        #backward and optimizer step
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

data={
    "model_state":model.state_dict(),
    "input_size":input_size,
    "output_size":output_size,
    "hidden_size":hidden_size,
    "all_words":all_words,
    "tags":tags
}
FILE="data.pth"
torch.save(data,FILE)
print(f"training complete. file saved to {FILE}")

import random
data=torch.load(FILE)
input_size=data["input_size"]
hidden_size=data["hidden_size"]
output_size=data["output_size"]
all_words=data["all_words"]
tags=data["tags"]
model_state=data["model_state"]
model=NeuralNet(input_size,hidden_size,output_size).to(device)
model.load_state_dict(model_state)
model.eval()

def response(sentence):
  sentence=tokenize(sentence)
  x=bag_of_words(sentence,all_words)
  x=x.reshape(1,x.shape[0])
  x=torch.from_numpy(x)

  output=model(x)
  _, predicted=torch.max(output,dim=1)
  tag=tags[predicted.item()]
  probs=torch.softmax(output,dim=1)
  prob=probs[0][predicted.item()]

  if prob.item()>0.75:
    for intent in intents["intents"]:
      if tag==intent["tag"]:
        return random.choice(intent["responses"]) 
  else:
    return ("I do not understand")

!pip install pyTelegramBotAPI

bot_API="5834870389:AAE1zje9dBYaX9XepR5V4mBlzJ3cgVYZlyM"
import telebot
bot=telebot.TeleBot(bot_API,parse_mode=None)

@bot.message_handler(commands=['start', 'help'])
def send_welcome(message):
	bot.reply_to(message, "how are you doing?")
 
@bot.message_handler(func=lambda message: True)
def echo_all(message):
	bot.reply_to(message, response(message.text))

bot.infinity_polling()